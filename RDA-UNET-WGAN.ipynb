{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RDA-UNET-WGAN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1TlchIW89R4j1QcipM9ELQhPxgYfFN6xv","authorship_tag":"ABX9TyOlgjrsbtorM/6pvwa13DDx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OMf8l6ZJ8Tp","executionInfo":{"status":"ok","timestamp":1627989080662,"user_tz":-120,"elapsed":230,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}},"outputId":"53c797a5-7a30-4cec-8f39-c170c07ce44f"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug  3 11:11:20 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEzi30oUUjKo","executionInfo":{"status":"ok","timestamp":1627989082226,"user_tz":-120,"elapsed":1298,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}},"outputId":"d2b6cb05-5c71-4fd0-d076-5cd05d8f1f6a"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AmR7FZojHN3h","executionInfo":{"status":"ok","timestamp":1627989082640,"user_tz":-120,"elapsed":420,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["import cv2\n","import PIL\n","from PIL import Image\n","import random\n","import imgaug\n","from imgaug import augmenters as iaa\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import sys\n","import time"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXOty8QGH9SN","executionInfo":{"status":"ok","timestamp":1627989083561,"user_tz":-120,"elapsed":927,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["import torch.nn as nn\n","import torch\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","import torch.nn.functional as F\n","from torchvision import transforms"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LOq7dwjT4Pi","executionInfo":{"status":"ok","timestamp":1627989083562,"user_tz":-120,"elapsed":36,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["sys.path.insert(0, '/content/drive/My Drive/Iñaki.Martínez/Code')\n","\n","from dataset_handler import DataSet\n","from segmentation_metrics import get_evaluation_metrics"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlILrsMhILT8","executionInfo":{"status":"ok","timestamp":1627989083563,"user_tz":-120,"elapsed":33,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["RANDOM_SEED = 42\n","\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","imgaug.seed(RANDOM_SEED)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"yfm8OHROIzkH","executionInfo":{"status":"ok","timestamp":1627989083565,"user_tz":-120,"elapsed":30,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["N_EPOCHS = 450\n","INITIAL_EPOCH = 1\n","GENERATOR_LEARNING_RATE = 0.00005\n","DISCRIMINATOR_LEARNING_RATE = 0.00005"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anA9o1ltJAO4","executionInfo":{"status":"ok","timestamp":1627989083566,"user_tz":-120,"elapsed":29,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}},"outputId":"47307ea7-ed87-4912-ea03-94c8a80fd74f"},"source":["ngpu = 1\n","DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","print(f\"Pytorch device: {DEVICE}\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Pytorch device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iH2Y4uSTJmPz","executionInfo":{"status":"ok","timestamp":1627989083576,"user_tz":-120,"elapsed":37,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["WEIGHTS_PATH = \"/content/drive/MyDrive/Iñaki.Martínez/Code/weights/rda-unet-wgan-weights\"\n","PRETRAINED_WEIGHTS = False"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rPJh1eaKS4a","executionInfo":{"status":"ok","timestamp":1627989083579,"user_tz":-120,"elapsed":37,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["N_CRITIC = 5"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UgEH4_uKla2","executionInfo":{"status":"ok","timestamp":1627989083580,"user_tz":-120,"elapsed":37,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["TRAIN_DATA_DIR = \"/content/drive/MyDrive/Iñaki.Martínez/Datasets/Dataset of Breast Ultrasound Images (Aldhyabani et al.)\"\n","TRAIN_DATA_ANNOTATIONS_FILE = \"gan_train_bus_images.csv\"\n","VAL_DATA_FILE = \"/content/drive/MyDrive/Iñaki.Martínez/Datasets/Dataset of Breast Ultrasound Images (Aldhyabani et al.)\"\n","VAL_DATA_ANNOTATIONS_FILE = \"gan_val_bus_images.csv\"\n","\n","BATCH_SIZE = 64\n","\n","DATA_LOADERS_CORE_NUMBER = 2"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmaLowzbLiZj","executionInfo":{"status":"ok","timestamp":1627989083581,"user_tz":-120,"elapsed":34,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["def load_img_transforms():\n","\n","    \"\"\"\n","    Funcion que carga las transformaciones\n","\n","    :return:\n","    \"\"\"\n","    train_data_transform = transforms.Compose([\n","        transforms.Resize((128, 128), interpolation=PIL.Image.NEAREST),\n","        transforms.ToTensor()\n","    ])\n","\n","    val_data_transform = train_data_transform\n","\n","    return train_data_transform, val_data_transform"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjVtJ2b01FyG","executionInfo":{"status":"ok","timestamp":1627989083582,"user_tz":-120,"elapsed":32,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["def weights_init(m):\n","\n","    \"\"\"\n","    Inicializacion de los pesos de la red\n","\n","    :param m: red\n","    :return:\n","    \"\"\"\n","    classname = m.__class__.__name__\n","\n","    if classname == 'DilationConvolutionsChain':\n","        pass\n","    else:\n","        if classname.find('Conv') != -1:\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","        elif classname.find('BatchNorm') != -1:\n","            nn.init.normal_(m.weight.data, 1.0, 0.02)\n","            nn.init.constant_(m.bias.data, 0)\n","\n","\n","def merge_images_with_masks(images, masks):\n","\n","    \"\"\"\n","    Genera las imagenes de 4 canales que se pasan al discriminador (3 de la imagen original + 1 con\n","    la mascara de segmentacion\n","\n","    :param images: imagenes\n","    :param masks: mascaras de segmentacion\n","    :return: tensor con imagenes de 4 canales\n","    \"\"\"\n","\n","    batch_size = images.shape[0]\n","    img_dim = images.shape[2]\n","    merged = torch.rand(batch_size, 4, img_dim, img_dim)\n","\n","    for i in range(batch_size):\n","        merged[i] = torch.cat((images[i], masks[i]))\n","\n","    return merged\n","\n","\n","def gradient_penalty(critic, real_data, fake_data, penalty, device):\n","\n","    n_elements = real_data.nelement()\n","    batch_size = real_data.size()[0]\n","    colors = real_data.size()[1]\n","    image_width = real_data.size()[2]\n","    image_height = real_data.size()[3]\n","    alpha = torch.rand(batch_size, 1).expand(batch_size, int(n_elements / batch_size)).contiguous()\n","    alpha = alpha.view(batch_size, colors, image_width, image_height).to(device)\n","\n","    fake_data = fake_data.view(batch_size, colors, image_width, image_height)\n","    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n","\n","    interpolates = interpolates.to(device)\n","    interpolates.requires_grad_(True)\n","    critic_interpolates = critic(interpolates)\n","\n","    gradients = torch.autograd.grad(\n","        outputs=critic_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=torch.ones(critic_interpolates.size()).to(device),\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True\n","    )[0]\n","\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * penalty\n","\n","    return gradient_penalty"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSisHPXWinTq","executionInfo":{"status":"ok","timestamp":1627989084245,"user_tz":-120,"elapsed":694,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":["from sklearn.metrics import roc_curve, precision_recall_curve, auc\n","\n","class SegmentationEvaluationMetrics:\n","\n","    def __init__(self, CCR, precision, recall, sensibility, specifity, f1_score,\n","                 jaccard, dice, roc_auc, precision_recall_auc, hausdorf_error):\n","        self.CCR = CCR\n","        self.precision = precision\n","        self.recall = recall\n","        self.sensibility = sensibility\n","        self.specifity = specifity\n","        self.f1_score = f1_score\n","        self.jaccard = jaccard\n","        self.dice = dice\n","        self.roc_auc = roc_auc\n","        self.precision_recall_auc = precision_recall_auc\n","        self.hausdorf_error = hausdorf_error\n","\n","\n","def compute_jaccard_dice_coeffs(mask1, mask2):\n","    \"\"\"Calculates the dice coefficient for the images\"\"\"\n","\n","    mask1 = np.asarray(mask1).astype(np.bool)\n","    mask2 = np.asarray(mask2).astype(np.bool)\n","\n","    if mask1.shape != mask2.shape:\n","        raise ValueError(\"Shape mismatch: mask1 and mask2 must have the same shape.\")\n","\n","    mask1 = mask1 > 0.5\n","    mask2 = mask2 > 0.5\n","\n","    im_sum = mask1.sum() + mask2.sum()\n","\n","    if im_sum == 0:\n","        return 1.0\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(mask1, mask2).sum()\n","    union = im_sum - intersection\n","\n","    return intersection / union, 2. * intersection / im_sum\n","\n","def compute_jaccard_coeff(mask1, im2):\n","    \"\"\"Calculates the jaccard coefficient for the images\"\"\"\n","\n","    mask1 = np.asarray(mask1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if mask1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    mask1 = mask1 > 0.5\n","    im2 = im2 > 0.5\n","\n","    im_sum = mask1.sum() + im2.sum()\n","    if im_sum == 0:\n","        return 1.0\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(mask1, im2).sum()\n","    union = im_sum - intersection\n","    return intersection / union\n","\n","\n","def get_conf_mat(prediction, groundtruth):\n","    \"\"\"Computes scores:\n","    FP = False Positives\n","    FN = False Negatives\n","    TP = True Positives\n","    TN = True Negatives\n","    return: FP, FN, TP, TN\"\"\"\n","\n","    prediction = prediction > 0.5\n","    groundtruth = groundtruth > 0.5\n","\n","    FP = np.float(np.sum((prediction == 1) & (groundtruth == 0)))\n","    FN = np.float(np.sum((prediction == 0) & (groundtruth == 1)))\n","    TP = np.float(np.sum((prediction == 1) & (groundtruth == 1)))\n","    TN = np.float(np.sum((prediction == 0) & (groundtruth == 0)))\n","\n","\n","    return FP, FN, TP, TN\n","\n","\n","def merge_images_with_masks(images, masks):\n","\n","    \"\"\"\n","    Genera las imagenes de 4 canales que se pasan al discriminador (3 de la imagen original + 1 con\n","    la mascara de segmentacion\n","\n","    :param images: imagenes\n","    :param masks: mascaras de segmentacion\n","    :return: tensor con imagenes de 4 canales\n","    \"\"\"\n","\n","    batch_size = images.shape[0]\n","    img_dim = images.shape[2]\n","    merged = torch.rand(batch_size, 4, img_dim, img_dim)\n","\n","    for i in range(batch_size):\n","        merged[i] = torch.cat((images[i], masks[i]))\n","\n","    return merged\n","\n","\n","def get_evaluation_metrics2(epoch, dataloader, segmentor, DEVICE, writer=None, SAVE_SEGS=False, COLOR=True,\n","                           N_EPOCHS_SAVE=10, folder=\"\"):\n","\n","    save_folder = os.path.join(folder, f\"epoch_{epoch}\")\n","\n","    if SAVE_SEGS and epoch % N_EPOCHS_SAVE == 0:\n","      if not os.path.isdir(save_folder):\n","          os.mkdir(save_folder)\n","\n","    ccrs = []\n","\n","    precisions = []\n","    recalls = []\n","\n","    sensibilities = []\n","    specifities = []\n","\n","    f1_scores = []\n","\n","    jaccard_coefs = []\n","    dice_coeffs = []\n","\n","    roc_auc_coeffs = []\n","    precision_recall_auc_coeffs = []\n","\n","    hausdorf_errors = []\n","\n","    segmentor.eval()\n","\n","    with torch.no_grad():\n","\n","        for i, batched_sample in enumerate(dataloader):\n","\n","          images, masks, filenames = batched_sample[\"image\"].to(DEVICE), batched_sample[\"mask\"].to(DEVICE), \\\n","                                     batched_sample[\"filename\"]\n","\n","          segmentations = segmentor(images)\n","          segmentations = torch.autograd.Variable((segmentations > 0.5).float())\n","          \n","          trans = transforms.ToPILImage()\n","\n","          for j in range(images.shape[0]):\n","              image, mask = images[j].to(\"cpu\"), masks[j].to(\"cpu\")\n","              segmentation = segmentations[j].to(\"cpu\")\n","              name = filenames[j].split('/')[-1]\n","\n","              FP, FN, TP, TN = get_conf_mat(segmentation.numpy(), mask.numpy())\n","\n","              # print(f\"FP = {FP}, FN = {FN}, TP = {TP}, TN = {TN}, TOTAL = {FP + FN + TP + TN}\")\n","\n","              ccr = np.divide(TP + TN, FP + FN + TP + TN)\n","\n","              precision = np.divide(TP, TP + FP)\n","              recall = np.divide(TP, TP + FN)\n","\n","              sensibility = np.divide(TP, TP + FN)\n","              specifity = np.divide(TN, TN + FP)\n","\n","              f1_score = 2 * np.divide(precision * recall, precision + recall)\n","\n","              jaccard_coef, dice_coeff = compute_jaccard_dice_coeffs(segmentation.numpy(), mask.numpy())\n","\n","              mask_labels = mask.numpy().ravel().astype(np.int32)\n","              segmentation_labels = segmentation.numpy().ravel()\n","              fpr, tpr, _ = roc_curve(mask_labels, segmentation_labels)\n","              roc_auc = auc(fpr,tpr)\n","\n","              precision_values, recall_values, _ = precision_recall_curve(mask_labels, segmentation_labels)\n","              precision_recall_auc = auc(recall_values, precision_values)\n","\n","\n","              hausdorf_error = 12.0\n","\n","              ccrs.append(ccr)\n","              precisions.append(precision)\n","              recalls.append(recall)\n","              sensibilities.append(sensibility)\n","              specifities.append(specifity)\n","              f1_scores.append(f1_score)\n","              jaccard_coefs.append(jaccard_coef)\n","              dice_coeffs.append(dice_coeff)\n","              roc_auc_coeffs.append(roc_auc)\n","              precision_recall_auc_coeffs.append(precision_recall_auc)\n","              hausdorf_errors.append(hausdorf_error)\n","\n","              if SAVE_SEGS and epoch % N_EPOCHS_SAVE == 0:\n","\n","                  image_save = trans(image)\n","                  mask_save = trans(mask)\n","                  segmentation_save = trans(segmentation)\n","\n","                  opencv_image = np.array(image_save)\n","                  opencv_image = opencv_image[:, :, ::-1].copy()\n","                  opencv_gt = np.array(mask_save)\n","                  opencv_segmentation = np.array(segmentation_save)\n","                  opencv_segmentation = np.where(opencv_segmentation>0.5, 1.0, 0.0)\n","\n","                  if not COLOR:\n","                      img = np.vstack(\n","                          (cv2.cvtColor(opencv_image, cv2.COLOR_RGB2GRAY), opencv_gt, opencv_segmentation))\n","                      cv2.imwrite(os.path.join(save_folder, f\"{name}.png\"), img)\n","\n","                  else:\n","                      contours_gt, hierarchy = cv2.findContours(opencv_gt, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","                      contours_seg, hierarchy = cv2.findContours(opencv_segmentation, cv2.RETR_TREE,\n","                                                                  cv2.CHAIN_APPROX_SIMPLE)\n","\n","                      cv2.drawContours(opencv_image, contours_gt, -1, (0, 255, 0), 1)\n","                      cv2.drawContours(opencv_image, contours_seg, -1, (0, 0, 255), 1)\n","\n","                      cv2.imwrite(os.path.join(save_folder, f\"{name}.png\"), opencv_image)\n","\n","\n","        ccrs = np.array(ccrs)[~np.isnan(np.array(ccrs))]\n","        precisions = np.array(precisions)[~np.isnan(np.array(precisions))]\n","        recalls = np.array(recalls)[~np.isnan(np.array(recalls))]\n","        sensibilities = np.array(sensibilities)[~np.isnan(np.array(sensibilities))]\n","        specifities = np.array(specifities)[~np.isnan(np.array(specifities))]\n","        f1_scores = np.array(f1_scores)[~np.isnan(np.array(f1_scores))]\n","        jaccard_coefs = np.array(jaccard_coefs)[~np.isnan(np.array(jaccard_coefs))]\n","        dice_coeffs = np.array(dice_coeffs)[~np.isnan(np.array(dice_coeffs))]\n","        roc_auc_coeffs = np.array(roc_auc_coeffs)[~np.isnan(np.array(roc_auc_coeffs))]\n","        precision_recall_auc_coeffs = np.array(precision_recall_auc_coeffs)[~np.isnan(np.array(precision_recall_auc_coeffs))]\n","        hausdorf_errors = np.array(hausdorf_errors)[~np.isnan(np.array(hausdorf_errors))]\n","\n","        mean_ccr = np.nansum(ccrs) / len(ccrs)\n","        std_ccr = np.std(np.array(ccrs))\n","\n","        mean_precision = np.nansum(precisions) / len(precisions)\n","        std_precision = np.std(np.array(precisions))\n","\n","        mean_recall = np.nansum(recalls) / len(recalls)\n","        std_recall = np.std(np.array(recalls))\n","\n","        mean_sensibility = np.nansum(sensibilities) / len(sensibilities)\n","        std_sensibility = np.std(np.array(sensibilities))\n","\n","        mean_specifity = np.nansum(specifities) / len(specifities)\n","        std_specifity = np.std(np.array(specifities))\n","\n","        mean_f1_score = np.nansum(f1_scores) / len(f1_scores)\n","        std_f1_score = np.std(np.array(f1_scores))\n","\n","        mean_jaccard_coef = np.nansum(jaccard_coefs) / len(jaccard_coefs)\n","        std_jaccard_coef = np.std(np.array(jaccard_coefs))\n","\n","        mean_dice_coeff = np.nansum(dice_coeffs) / len(dice_coeffs)\n","        std_dice_coeff = np.std(np.array(dice_coeffs))\n","\n","        mean_roc_auc = np.nansum(roc_auc_coeffs) / len(roc_auc_coeffs)\n","        std_roc_auc = np.std(np.array(roc_auc_coeffs))\n","\n","        precision_recall_auc = np.nansum(precision_recall_auc_coeffs) / len(precision_recall_auc_coeffs)\n","        std_roc_auc = np.std(np.array(precision_recall_auc_coeffs))\n","\n","        mean_hausdorf_error = np.nansum(hausdorf_errors) / len(hausdorf_errors)\n","        std_hausdorf_error = np.std(np.array(hausdorf_errors))\n","\n","        if writer is not None:\n","          writer.add_scalar(\"Metrics/ccr\", mean_ccr, epoch)\n","          writer.add_scalar(\"Metrics/precision\", mean_precision, epoch)\n","          writer.add_scalar(\"Metrics/recall\", mean_recall, epoch)\n","          writer.add_scalar(\"Metrics/sensibility\", mean_sensibility, epoch)\n","          writer.add_scalar(\"Metrics/specifity\", mean_specifity, epoch)\n","          writer.add_scalar(\"Metrics/f1 score\", mean_f1_score, epoch)\n","          writer.add_scalar(\"Metrics/jaccard idx\", mean_jaccard_coef, epoch)\n","          writer.add_scalar(\"Metrics/dice coeff\", mean_dice_coeff, epoch)\n","          writer.add_scalar(\"Metrics/roc-auc\", mean_roc_auc, epoch)\n","          writer.add_scalar(\"Metrics/precision recall auc\", precision_recall_auc, epoch)\n","          writer.add_scalar(\"Metrics/hausdorf error\", mean_hausdorf_error, epoch)\n","\n","        return SegmentationEvaluationMetrics(mean_ccr, mean_precision, mean_recall,\n","         mean_sensibility, mean_specifity, mean_f1_score, mean_jaccard_coef,\n","         mean_dice_coeff, mean_roc_auc, precision_recall_auc, mean_hausdorf_error)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HPsGPFsSMSmb","executionInfo":{"status":"error","timestamp":1627989272888,"user_tz":-120,"elapsed":188649,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}},"outputId":"b6353f0d-dcf0-4511-9169-35ea15af576e"},"source":["sys.path.insert(0, '/content/drive/My Drive/Iñaki.Martínez/Code')\n","\n","from dataset_handler import DataSet\n","from rdau_net import RDAU_NET\n","from discriminator import Discriminator\n","\n","\n","#writer = SummaryWriter('/content/drive/My Drive/Iñaki.Martínez/Code/runs/tensorboard_log')\n","torch.manual_seed(RANDOM_SEED)\n","train_data_transform, val_data_transform = load_img_transforms()\n","\n","transforms_dict = {\n","    \"train\": train_data_transform,\n","    \"val\": train_data_transform,\n","    \"test\": train_data_transform\n","}\n","\n","augmentation_dict = {\n","    \"train\": None,\n","    \"val\": None,\n","    \"test\": None\n","}\n","\n","dataset = DataSet(TRAIN_DATA_DIR, TRAIN_DATA_ANNOTATIONS_FILE,TRAIN_DATA_ANNOTATIONS_FILE,TRAIN_DATA_ANNOTATIONS_FILE, transforms_dict, augmentation_dict, BATCH_SIZE, 2)\n","\n","generator = RDAU_NET().to(DEVICE)\n","generator.apply(weights_init)\n","\n","discriminator = Discriminator().to(DEVICE)\n","discriminator.apply(weights_init)\n","\n","if PRETRAINED_WEIGHTS:\n","  generator.load_state_dict(torch.load(os.path.join(WEIHGHTS_PATH, \"generator_weights\")))\n","  discriminator.load_state_dict(torch.load(os.path.join(WEIHGHTS_PATH, \"discriminator_weights\")))\n","\n","optimizerD = optim.RMSprop(discriminator.parameters(), lr=DISCRIMINATOR_LEARNING_RATE)\n","optimizerG = optim.RMSprop(generator.parameters(), lr=GENERATOR_LEARNING_RATE)\n","\n","G_losses = []\n","D_losses = []\n","\n","log_filename = \"/content/drive/My Drive/Iñaki.Martínez/Code/execution_log.csv\"\n","with open(log_filename, 'w') as file:\n","  file.write(\"epoch,generator_loss,critic_loss,ccr,precision,recall,sensibility,specifity,f1_score,jaccard_coef,dsc_coef,roc_auc,pr_auc,hausdorf_error\\n\")\n","\n","for epoch in range(INITIAL_EPOCH, INITIAL_EPOCH+N_EPOCHS-1):\n","\n","  t_init = time.time()\n","\n","\n","  for i, batched_sample in enumerate(dataset.trainset_loader):\n","\n","    ############################\n","    #### DISCRIMINATOR ########\n","    #########################\n","\n","    optimizerD.zero_grad()\n","\n","    generator.eval()\n","    discriminator.train()\n","\n","    images, masks = batched_sample[\"image\"].to(DEVICE), batched_sample[\"mask\"].to(DEVICE)\n","\n","    images_with_gt = merge_images_with_masks(images, masks).to(DEVICE)\n","\n","    segmentations = generator(images).detach()\n","    #segmentations = torch.autograd.Variable((segmentations > 0.5).float(), requires_grad=True)\n","\n","    images_with_segmentations = merge_images_with_masks(images, segmentations).to(DEVICE)\n","\n","    loss_D = -torch.mean(discriminator(images_with_gt)) + torch.mean(discriminator(images_with_segmentations))\n","\n","    _gradient_penalty = gradient_penalty(discriminator, images_with_gt, images_with_segmentations, 10*2, DEVICE)\n","    loss_D += _gradient_penalty\n","\n","    loss_D.backward()\n","    optimizerD.step()\n","\n","    ############################\n","    #### GENERATOR ########\n","    #########################\n","\n","    if epoch % N_CRITIC == 0:\n","\n","      generator.train()\n","      discriminator.eval()\n","\n","      optimizerG.zero_grad()\n","\n","      segmentations = generator(images)\n","      generated_segmentations = merge_images_with_masks(images, segmentations).to(DEVICE)\n","\n","      loss_G = -torch.mean(discriminator(generated_segmentations))\n","\n","      loss_G.backward()\n","      optimizerG.step()\n","\n","      #writer.add_scalar(\"Train loss/generator\", loss_G.item(), epoch * len(dataset.trainset_loader) + i)\n","      #writer.add_scalar(\"Train loss/discriminator\", loss_D.item(), epoch * len(dataset.trainset_loader) + i)\n","\n","      if i % 5 == 0 or i % len(dataset.trainset_loader)+1 == len(dataset.trainset_loader):\n","        print(\n","        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","        % (epoch, N_EPOCHS, i % len(dataset.trainset_loader)+1, len(dataset.trainset_loader), loss_D.item(), loss_G.item())\n","        )\n","\n","      # Encolamos los costes para calcular el medio de la epoch cuando esta termine\n","      G_losses.append(loss_G.item())\n","      D_losses.append(loss_D.item())\n","\n","    else:\n","      if i % 5 == 0 or i % len(dataset.trainset_loader)+1 == len(dataset.trainset_loader):\n","        print(\n","        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: -]\"\n","        % (epoch, N_EPOCHS, i % len(dataset.trainset_loader)+1, len(dataset.trainset_loader), loss_D.item())\n","        )\n","\n","      #writer.add_scalar(\"Train loss/discriminator\", loss_D.item(), epoch * len(dataset.trainset_loader) + i)\n","      D_losses.append(loss_D.item())\n","\n","    #break\n","\n","  #if len(G_losses) > 0:\n","  #  writer.add_scalar(\"Per epoch train loss/generator\", np.mean(np.array(G_losses)), epoch)\n","  #writer.add_scalar(\"Per epoch train loss/discriminator\", np.mean(np.array(D_losses)), epoch)\n","\n","  \n","\n","  torch.save(generator.state_dict(), os.path.join(WEIGHTS_PATH, \"generator_weights\"))\n","  torch.save(discriminator.state_dict(), os.path.join(WEIGHTS_PATH, \"discriminator_weights\"))\n","\n","  metrics = get_evaluation_metrics2(epoch, dataset.trainset_loader, generator, DEVICE, SAVE_SEGS=True,\n","                         COLOR=True, N_EPOCHS_SAVE=10, folder='/content/drive/My Drive/Iñaki.Martínez/Code/inference')\n","  \n","  if len(G_losses) > 0:\n","    generator_loss = np.mean(np.array(G_losses))\n","  else:\n","    generator_loss = np.nan\n","\n","  with open(log_filename, 'a') as file:\n","    file.write(f\"{epoch},{generator_loss},{np.mean(np.array(D_losses))},{metrics.CCR},{metrics.precision},{metrics.recall},{metrics.sensibility},{metrics.specifity},{metrics.f1_score},{metrics.jaccard},{metrics.dice},{metrics.roc_auc},{metrics.precision_recall_auc},{metrics.hausdorf_error}\\n\")\n","\n","  G_losses = []\n","  D_losses = []\n","  \n","  t_end = time.time()\n","  print(\"Elapsed time for epoch {}: {:.2f}s\".format(epoch, t_end-t_init))\n","\n","  #break"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train set length: 453\n","Val set length: 453\n","Test set length: 453\n","Mini-batches size:\n","\tTrain set: 8\n","\tVal set: 8\n","\tTest set: 8\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 1/450] [Batch 1/8] [D loss: 13491.838867] [G loss: -]\n","[Epoch 1/450] [Batch 6/8] [D loss: 120.573013] [G loss: -]\n","[Epoch 1/450] [Batch 8/8] [D loss: 93.885155] [G loss: -]\n","Elapsed time for epoch 1: 16.35s\n","[Epoch 2/450] [Batch 1/8] [D loss: 78.388390] [G loss: -]\n","[Epoch 2/450] [Batch 6/8] [D loss: 41.509762] [G loss: -]\n","[Epoch 2/450] [Batch 8/8] [D loss: 61.103485] [G loss: -]\n","Elapsed time for epoch 2: 16.52s\n","[Epoch 3/450] [Batch 1/8] [D loss: 33.007534] [G loss: -]\n","[Epoch 3/450] [Batch 6/8] [D loss: 21.195820] [G loss: -]\n","[Epoch 3/450] [Batch 8/8] [D loss: 17.176867] [G loss: -]\n","Elapsed time for epoch 3: 16.78s\n","[Epoch 4/450] [Batch 1/8] [D loss: 23.244871] [G loss: -]\n","[Epoch 4/450] [Batch 6/8] [D loss: 11.453063] [G loss: -]\n","[Epoch 4/450] [Batch 8/8] [D loss: 19.081400] [G loss: -]\n","Elapsed time for epoch 4: 16.67s\n","[Epoch 5/450] [Batch 1/8] [D loss: 10.027678] [G loss: 1.546457]\n","[Epoch 5/450] [Batch 6/8] [D loss: 6.837816] [G loss: -2.674353]\n","[Epoch 5/450] [Batch 8/8] [D loss: 0.581030] [G loss: -3.809225]\n","Elapsed time for epoch 5: 24.80s\n","[Epoch 6/450] [Batch 1/8] [D loss: 3.171062] [G loss: -]\n","[Epoch 6/450] [Batch 6/8] [D loss: 1.907044] [G loss: -]\n","[Epoch 6/450] [Batch 8/8] [D loss: 4.852654] [G loss: -]\n","Elapsed time for epoch 6: 19.11s\n","[Epoch 7/450] [Batch 1/8] [D loss: 3.411206] [G loss: -]\n","[Epoch 7/450] [Batch 6/8] [D loss: 0.484051] [G loss: -]\n","[Epoch 7/450] [Batch 8/8] [D loss: -0.080989] [G loss: -]\n","Elapsed time for epoch 7: 16.49s\n","[Epoch 8/450] [Batch 1/8] [D loss: -1.324548] [G loss: -]\n","[Epoch 8/450] [Batch 6/8] [D loss: -2.257599] [G loss: -]\n","[Epoch 8/450] [Batch 8/8] [D loss: 0.295191] [G loss: -]\n","Elapsed time for epoch 8: 19.69s\n","[Epoch 9/450] [Batch 1/8] [D loss: -4.138852] [G loss: -]\n","[Epoch 9/450] [Batch 6/8] [D loss: -5.586047] [G loss: -]\n","[Epoch 9/450] [Batch 8/8] [D loss: -7.892107] [G loss: -]\n","Elapsed time for epoch 9: 16.64s\n","[Epoch 10/450] [Batch 1/8] [D loss: -4.566164] [G loss: -6.494001]\n","[Epoch 10/450] [Batch 6/8] [D loss: -4.188472] [G loss: -8.688125]\n","[Epoch 10/450] [Batch 8/8] [D loss: 0.146603] [G loss: -8.823410]\n"],"name":"stdout"},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c0ea1da69012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   metrics = get_evaluation_metrics2(epoch, dataset.trainset_loader, generator, DEVICE, SAVE_SEGS=True,\n\u001b[0;32m--> 133\u001b[0;31m                          COLOR=True, N_EPOCHS_SAVE=10, folder='/content/drive/My Drive/Iñaki.Martínez/Code/inference')\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-a278f6463141>\u001b[0m in \u001b[0;36mget_evaluation_metrics2\u001b[0;34m(epoch, dataloader, segmentor, DEVICE, writer, SAVE_SEGS, COLOR, N_EPOCHS_SAVE, folder)\u001b[0m\n\u001b[1;32m    208\u001b[0m                       \u001b[0mcontours_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopencv_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                       contours_seg, hierarchy = cv2.findContours(opencv_segmentation, cv2.RETR_TREE,\n\u001b[0;32m--> 210\u001b[0;31m                                                                   cv2.CHAIN_APPROX_SIMPLE)\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                       \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopencv_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"]}]},{"cell_type":"code","metadata":{"id":"7uHQ38qtTeFO","executionInfo":{"status":"aborted","timestamp":1627989272883,"user_tz":-120,"elapsed":32,"user":{"displayName":"Iñaki Martinez Garriz","photoUrl":"","userId":"11679360041219360753"}}},"source":[""],"execution_count":null,"outputs":[]}]}